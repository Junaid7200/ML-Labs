{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52009127",
   "metadata": {},
   "source": [
    "<div style=\"display:flex; justify-content:center\">\n",
    "<img src=\"image.png\">\n",
    "</div>\n",
    "<div style=\"display:flex; justify-content:center; margin:32px 0;\">\n",
    "  <table style=\"width:80%; max-width:900px; font-size:24px; border-collapse:collapse; border:2px solid #444;\">\n",
    "    <tr><th style=\"text-align:left; padding:10px; border:1px solid #444;\">Name:</th><td style=\"padding:10px; border:1px solid #444;\">Syed Junaid Jaffery</td></tr>\n",
    "    <tr><th style=\"text-align:left; padding:10px; border:1px solid #444;\">Class:</th><td style=\"padding:10px; border:1px solid #444;\">BSCS-A-7</td></tr>\n",
    "    <tr><th style=\"text-align:left; padding:10px; border:1px solid #444;\">Registration No:</th><td style=\"padding:10px; border:1px solid #444;\">22-NTU-CS-1167</td></tr>\n",
    "    <tr><th style=\"text-align:left; padding:10px; border:1px solid #444;\">Lab Report:</th><td style=\"padding:10px; border:1px solid #444;\">Ensemble Learning Report</td></tr>\n",
    "    <tr><th style=\"text-align:left; padding:10px; border:1px solid #444;\">Course Code:</th><td style=\"padding:10px; border:1px solid #444;\">AIC-3072L</td></tr>\n",
    "    <tr><th style=\"text-align:left; padding:10px; border:1px solid #444;\">Course Name:</th><td style=\"padding:10px; border:1px solid #444;\">Machine Learning Lab</td></tr>\n",
    "    <tr><th style=\"text-align:left; padding:10px; border:1px solid #444;\">Submitted To:</th><td style=\"padding:10px; border:1px solid #444;\"><em>Ms. Kainat Abdullah</em></td></tr>\n",
    "    <tr><th style=\"text-align:left; padding:10px; border:1px solid #444;\">Submission Date:</th><td style=\"padding:10px; border:1px solid #444;\">December 14, 2025</td></tr>\n",
    "  </table>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb0310b",
   "metadata": {},
   "source": [
    "## **1. Project Introduction and Goals**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c392c4",
   "metadata": {},
   "source": [
    "### **What is the main objectve of this machine learning project?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ae0517",
   "metadata": {},
   "source": [
    "Its basically an intro to ensemble models with an example of binary classification being done using several ensemble models. The main objective is to gain an understanding of different types of ensemble methods and which could be used when."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8a0db5",
   "metadata": {},
   "source": [
    "### **What is the speciÔ¨Åc task the model is being built to perform?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb2363d",
   "metadata": {},
   "source": [
    "He is trying to do binary classification on a dataset, The specific task is to correctly predict the class label which is either UP or DOWN, as in electricity prices going up or down."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c803c225",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de477b9f",
   "metadata": {},
   "source": [
    "## **2. Explaining Ensemble Learning**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052949e5",
   "metadata": {},
   "source": [
    "### **In simple terms, what is an \"ensemble model\"?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c168d9",
   "metadata": {},
   "source": [
    "An ensemble is simply a combination of multiple models to end up with a stronger overall model. The voting classifier that we have studied in Labs is an example of this actually so we have covered this to an extent already."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b535691",
   "metadata": {},
   "source": [
    "### **The notebook mentions three main categories of ensemble methods (Averaging, Boosting, Stacking). Briefly describe what each category does.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83da622d",
   "metadata": {},
   "source": [
    "1. Averaging (also known as bagging) is the simplest, we train multiple models of the same type (almost always decision trees) on random subsets of the dataset (for randomization, sampling with replacement technique is used), completly independent from eachother. We make predictions using each model, the majority vote wins.\n",
    "2. Boosting is when the models are not training independently, one model is supposed to specifically target the samples where the first model had high error. If we have two models x and y and we wanna train them using the boosting technique, model y would specifically train on the samples that model x failed on so they both combine to form a more robust model. Each model builds on the previous.\n",
    "3. Stacking is a 2 step process, first is the training of the base models, and the second step is a manager model trained on the predictions of the base models. The base models are diverse (in bagging and boosting we just use a bunch of models of the same type, mostly decision trees, but in stacking we gotta use diff types of models like svm + knn + decision tree + a simple ANN) and they provide their own independent predictions. A manager model is then trained on those predictions to provide the final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a90b92",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46fb5be",
   "metadata": {},
   "source": [
    "## **3. Data Exploration & Insights**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c43624",
   "metadata": {},
   "source": [
    "### **Describe the dataset used. What is the source and what does the target variable represent?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d6cac1",
   "metadata": {},
   "source": [
    "- Description: its a dataset about electricity with 45,312 samples and 8 features and one target class so a total of 9 columns. All the features are already numeric, the target class is categorical.\n",
    "- Source: its electrity dataset version 1 from the OpenMl website. You can import it directly from sklearn using sklearn.datasets.fetch_openml(name=\"electricity\", version=1)\n",
    "- Target: its the binary class label of either UP or DOWN indicating whether the electricity price has increased or decreased"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550989e2",
   "metadata": {},
   "source": [
    "### **Based on the Exploratory Data Analysis (EDA), what are two key findings about the data? (For example, discuss the distribution of the target variable or a relationship between features).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ea9ff4",
   "metadata": {},
   "source": [
    "- There are more DOWN label samples then UP label but it is not too heavily skewed that we need something like stratefied cross validation.\n",
    "- None of the features have such a high correlation that they become basically redundant so all features are valid. (although day is not normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84555c8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24658a6",
   "metadata": {},
   "source": [
    "## **4. Methodology & Planned Workflow**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b088685c",
   "metadata": {},
   "source": [
    "### **The notebook lists several specific ensemble algorithms to be implemented (e.g., Gradient Boosting, AdaBoost). Name two of them.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a240d1d0",
   "metadata": {},
   "source": [
    "You just named one in the question (adaboost) so thats one. I will list a few below:\n",
    "1. Bagging: RandomForest and BaggingClassifier from sklearn.ensemble.BaggingClassifier with KNN as the estimator.\n",
    "2. Boosting: AdaBoost, XGboost\n",
    "3. Stacking: stacking classifier from sklearn.ensemble with svc, knn, and random forest as base models, and logistic regressor as manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75532175",
   "metadata": {},
   "source": [
    "### **The code for training the models is not shown. Based on a typical Scikit-learn workflow, what are the main steps you would take to train one of these models after the data is preprocessed?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3068eb6",
   "metadata": {},
   "source": [
    "Here are the main steps after data preprocessing:\n",
    "1. split the data\n",
    "2. pick an ensemble model (eg random forest)\n",
    "3. set hyperparameters like n_estimators and learning rate etc.\n",
    "4. fit it on the training set\n",
    "5. predict on the testing set\n",
    "6. use accuracy_score from sklearn.metrics for quick evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53690e25",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e53263",
   "metadata": {},
   "source": [
    "## **5. Conclusion & Reasoning**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc18d986",
   "metadata": {},
   "source": [
    "### **Why do you think ensemble models are a suitable choice for predicting electricity price changes?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e4586b",
   "metadata": {},
   "source": [
    "The main issue that jumps to mind is that the data is complex and we need complex models to give reasonable accuracy, but complex models lead to overfitting in most cases. That scenario is perfect for using bagging so that is why ensemble methods (specifically bagging) would be perfect here. If the data is too complex for a bagging ensemble then boosting could be used since it does better then bagging on complex data. Whether you use bagging or boosting, both would generalize better then a single model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46aa7cff",
   "metadata": {},
   "source": [
    "### **If you were to complete this project, what would be the most important thing to check to see if the model is successful?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26ec20c",
   "metadata": {},
   "source": [
    "I don't know what exactly you mean by 'complete this project' but the logical next steps from where the notebook ends would be:\n",
    "- He checked accuracy but didn't graph a learning curve to check for overfitting. He didn't even use anyother metric other then accuracy. We should at least visualize a confusion matrix.\n",
    "- No hyperparameter tuning was actually done, you could use a validation set and try out different values of n_estimators etc to find out the best one (or just do gridsearchCV)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abeabcaa",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fafc45",
   "metadata": {},
   "source": [
    "### Word Count of the answers totaled: **731**\n",
    "\n",
    "its only 31 words over the given limit, hopefully not an issue."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
